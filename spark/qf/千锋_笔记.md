## day01
```

了解Spark

Spark集群安装（Standalone）

提交任务
/export/servers/spark-2.2.0-bin-hadoop2.6/bin/spark-submit \
--class com.qf.gp1922.day06.SparkWordCount --master spark://node01:7077 \
--executor-memory 512m \
--total-executor-cores 2 \
/root/1.jar hdfs://node01:9000/files \
hdfs://node01:9000/out-20190729-2

Spark的几个重要角色
	Master
	Worker
	Driver
	Executor

Spark Shell
	SparkShell是一个Spark的特殊的应用程序，因为我们可以在shell里再提交job，
	所以shell启动后，Spark的Driver端会启动SparkSubmit进程
	local模式启动：bin/spark-shell
	集群模式启动：
	spark-2.2.0-bin-hadoop2.6]# bin/spark-shell \
	--master spark://node01:7077 \
	--executor-memory 512m \
	--total-executor-cores 2

Spark WordCount

RDD的概念和特性
RDD是一个弹性的分布式数据集，是一个数据的描述，具有不可变，可分区等特性。
RDD提供了一系列对RDD的操作的方法。

A list of partitions
一系列的分区
A function for computing each split
一个函数会作用到每个分片
A list of dependencies on other RDDs
RDD之间是有依赖关系的
Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)
如果该RDD是key，value的RDD，会有一个分区器作用在该RDD上
Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)
位置优先性（就近原则）


```

千锋_RDD的依赖关系和数据优先计算：
![千锋_RDD的依赖关系和数据优先计算](/assets/千锋_RDD的依赖关系和数据优先计算.png)


千锋_Spark几个重要的组件：
![千锋_Spark几个重要的组件](/assets/千锋_Spark几个重要的组件.png)


## day02
```

RDD概念总结

RDD的弹性

创建RDD的两种方式

RDD的api：Transformation和Action
	map和mapPartitions的区别：
		map是将func作用于每一个元素上，而mapPartitions是将func作用于每个分区上，
		应用场景为：如果该RDD数据集的数据不是很多的情况下，可以用map处理，
		如果数据比较多，可以用mapPartitions，可以提高计算效率，
		如果数据量很大，有可能会导致oom
	
	重分区算子：
	repartition
	coalesce
	partitionBy
	repartitionAndSortWithinPartitions
	
	foreach和foreachPartition的区别：
		首先他们都没有返回值
		foreach是将func作用于每一个元素上，而foreachPartitions是将func作用于每个分区上，
		应用场景：一般都是用在将结果输出的场景，
		如果结果数据量很少，可以用foreach进行存储，
		如果数据量比较大，会拿很多的连接进行存储，可能数据库会直接宕机，可以用foreachPartiton，用一个分区对应一个连接

	collect：属于Action算子，会将每个Executor计算的结果汇总到Driver并将结果数据封装到Array
	
算子练习


RDD的概念一定要理解
理解transformation和action
自己总结今天练习的算子，能够灵活运用
其中重点掌握的算子有：
	map、mapPartition
	foreach、foreachPartition
	排序类算子
	聚合类算子
	重分区算子
	action类算子
```

spark rdd api.txt
```
http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
遍历类算子：map mapPartitions
val rdd1 = sc.parallelize(List(1,2,3,4,5,6), 2)
val rdd2 = rdd1.map(_ * 10)
val rdd2 = rdd1.mapPartitions(_.map(_ * 10))
rdd2.collect

mapPartitions   f: Iterator[T] => Iterator[U]
rdd1.mapPartitions(_.toList.reverse.iterator).collect

mapPartitionsWithIndex
参数列表：(f: (Int, Iterator[T]) => Iterator[U], preservesPartitioning: Boolean = false)
val func = (index: Int, iter: Iterator[(Int)]) => {
  iter.toList.map(x => "[partID:" +  index + ", val: " + x + "]").iterator
}
val rdd1 = sc.parallelize(List(1,2,3,4,5,6,7,8,9), 2)
rdd1.mapPartitionsWithIndex(func).collect

-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
排序类算子：
sortBykey
val rdd4 = sc.parallelize(Array((3,"aa"),(6,"cc"),(2,"bb"),(1,"dd")))
val sorted: RDD[(Int, String)] = rdd4.sortByKey()

sortBy
val rdd1 = sc.parallelize(List(5,6,4,7,3,8,2,9,10))
val rdd2: RDD[Int] = rdd1.sortBy(x => x, true)
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
重分区算子：
repartition
val rdd1 = sc.parallelize(1 to 10, 3)
val reps1 = rdd1.repartition(5)
reps1.partitions.length

coalesce
val rdd2 = rdd1.coalesce(2, false)
rdd2.partitions.length

partitionBy
val rdd1 = sc.parallelize(List(("e",5),("c",3),("d",4),("c",2),("a",1)),2)
val rdd2: RDD[(String, Int)] = rdd1.partitionBy(new HashPartitioner(4))
reps2.partitions.length

repartitionAndSortWithinPartitions
val rdd4 = sc.parallelize(Array((3,"aa"),(6,"cc"),(2,"bb"),(1,"dd")))
rdd4.repartitionAndSortWithinPartitions(new org.apache.spark.HashPartitioner(1)).foreach(println)

-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
聚合类算子：
aggregate
(zeroValue: U)(seqOp: (U, T) => U, combOp: (U, U) => U): U

def func1(index: Int, iter: Iterator[(Int)]) : Iterator[String] = {
  iter.toList.map(x => "[partID:" +  index + ", val: " + x + "]").iterator
}
val rdd1 = sc.parallelize(List(1,2,3,4,5,6,7,8,9), 2)
rdd1.mapPartitionsWithIndex(func1).collect
rdd1.aggregate(0)(math.max(_, _), _ + _)
rdd1.aggregate(5)(math.max(_, _), _ + _)


val rdd2 = sc.parallelize(List("a","b","c","d","e","f"),2)
def func2(index: Int, iter: Iterator[(String)]) : Iterator[String] = {
  iter.toList.map(x => "[partID:" +  index + ", val: " + x + "]").iterator
}
rdd2.mapPartitionsWithIndex(func2).collect
rdd2.aggregate("")(_ + _, _ + _)
rdd2.aggregate("=")(_ + _, _ + _)

val rdd3 = sc.parallelize(List("12","23","345","4567"),2)
rdd3.aggregate("")((x,y) => math.max(x.length, y.length).toString, (x,y) => x + y)

val rdd4 = sc.parallelize(List("12","23","345",""),2)
rdd4.aggregate("")((x,y) => math.min(x.length, y.length).toString, (x,y) => x + y)

val rdd5 = sc.parallelize(List("12","23","","345"),2)
rdd5.aggregate("")((x,y) => math.min(x.length, y.length).toString, (x,y) => x + y)

-------------------------------------------------------------------------------------------
aggregateByKey
(zeroValue: U, partitioner: Partitioner)(seqOp: (U, V) => U, combOp: (U, U) => U): RDD[(K, U)

val pairRDD = sc.parallelize(List(("mouse", 2),("cat",2), ("cat", 5), ("mouse", 4),("cat", 12), ("dog", 12)), 2)
def func2(index: Int, iter: Iterator[(String, Int)]) : Iterator[String] = {
  iter.toList.map(x => "[partID:" +  index + ", val: " + x + "]").iterator
}
pairRDD.mapPartitionsWithIndex(func2).collect
pairRDD.aggregateByKey(0)(math.max(_, _), _ + _).collect
pairRDD.aggregateByKey(100)(math.max(_, _), _ + _).collect

-------------------------------------------------------------------------------------------
combineByKey
第一个参数: 拿到分区内的第一个元素，并按照你给的函数进行返回相应的类型
第二个参数：局部聚合
第三个参数：全局聚合
(createCombiner: V => C, mergeValue: (C, V) => C, mergeCombiners: (C, C) => C)
val rdd1 = sc.textFile("hdfs://node01:9000/wc").flatMap(_.split(" ")).map((_, 1))
val rdd2 = rdd1.combineByKey(x => x, (a: Int, b: Int) => a + b, (m: Int, n: Int) => m + n)
rdd2.collect

val rdd3 = rdd1.combineByKey(x => x + 10, (a: Int, b: Int) => a + b, (m: Int, n: Int) => m + n)
rdd3.collect

val rdd4 = sc.parallelize(List("dog","cat","gnu","salmon","rabbit","turkey","wolf","bear","bee"), 3)
val rdd5 = sc.parallelize(List(1,1,2,2,2,1,2,2,2), 3)
val rdd6 = rdd5.zip(rdd4)
val rdd7 = rdd6.combineByKey(List(_), (x: List[String], y: String) => x :+ y, (m: List[String], n: List[String]) => m ++ n)

-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
action类算子：
val rdd1 = sc.parallelize(List(2,1,3,6,5),2)
reduce、count、top、take、takeOrdered、first

countByKey、countByValue
val rdd1 = sc.parallelize(List(("a", 1), ("b", 2), ("b", 2), ("c", 2), ("c", 1)))
rdd1.countByKey
rdd1.countByValue

foreach、foreachPartition
val rdd1 = sc.parallelize(List(1, 2, 3, 4, 5, 6, 7, 8, 9), 3)
rdd1.foreachPartition(x => println(x.reduce(_ + _)))

-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
其他算子：
filterByRange
val rdd1 = sc.parallelize(List(("e", 5), ("c", 3), ("d", 4), ("c", 2), ("a", 1)))
val rdd2 = rdd1.filterByRange("c", "d")
rdd2.collect
-------------------------------------------------------------------------------------------
flatMapValues
val rdd3 = sc.parallelize(List(("a", "1 2"), ("b", "3 4")))
rdd3.flatMapValues(_.split(" "))
-------------------------------------------------------------------------------------------
foldByKey
val rdd1 = sc.parallelize(List("dog", "wolf", "cat", "bear"), 2)
val rdd2 = rdd1.map(x => (x.length, x))
val rdd3 = rdd2.foldByKey("")(_+_)

val rdd = sc.textFile("hdfs://node01:9000/wc").flatMap(_.split(" ")).map((_, 1))
rdd.foldByKey(0)(_+_)
-------------------------------------------------------------------------------------------
keyBy
val rdd1 = sc.parallelize(List("dog", "salmon", "salmon", "rat", "elephant"), 3)
val rdd2 = rdd1.keyBy(_.length)
rdd2.collect
-------------------------------------------------------------------------------------------
keys values
val rdd1 = sc.parallelize(List("dog", "tiger", "lion", "cat", "panther", "eagle"), 2)
val rdd2 = rdd1.map(x => (x.length, x))
rdd2.keys.collect
rdd2.values.collect
-------------------------------------------------------------------------------------------
collectAsMap
val rdd = sc.parallelize(List(("a", 1), ("b", 2)))
rdd.collectAsMap
-------------------------------------------------------------------------------------------

```



groupByKey和reduceByKey：
![千锋_groupByKey和reduceByKey](/assets/千锋_groupByKey和reduceByKey.png)


## day03
```

独立IP数
pv、uv属于统计网站的访问量
pv：用用户请求的ip地址来计算用户访问的网站的页面的次数
	该需求的统计具有真实性，是衡量网站流量的重要指标
uv：可以理解为访问某网站的电脑的数量
	网站判断来访电脑的身份是通过来访电脑的cookies实现的，往往是按天来统计
	如果更换了ip后但不清除cookies，再访问相同的网站，该网站的统计的uv数是不变的

pv、uv一般是用作网站流量的趋势分析、数据对比分析、数据细分分析这三个维度
对比分析，就是给孤立的数据一个合理的参考系
GMV=销售额+取消订单金额+拒收订单金额+退货订单金额
环比：某年的1月的销量和该年的2月的销量的比较
同比：某年的1月的销量和前年的1月的销量的比较
定基比：以一个时间范围作为基点，其他时间范围的数量和基点进行比较

pvuv：
	val logs = sc.textFile("...")
	val ip = logs.map(_.split(" ")(0))
	val pv = ip.count
	val uv = pv.distinct


TextFile分区过程

案例练习

RDD的对象传递

RDD的依赖关系

DAG
```


join的宽依赖:
![千锋_join的宽依赖](/assets/千锋_join的宽依赖.png)


## day04
```

DAG、Stage划分、task的生成
	Application：应用程序
		输入、计算、输出
	Job：Action和之前的所有Transformation属于一个Job
		计算一个应用程序有几个Job，只需要计算有几个Action即可
	Stage：将RDD进行范围描述的过程称为Stage的划分，
		Stage划分的目的是为了生成task
		Stage划分的依据是查看RDD和它的父RDD之间的依赖关系，如果是宽依赖，则划分Stage
	Task：Executor执行的最小单元就是task，
		task包含了需要计算的对应的一个分区的数据，还包含了计算过程，每个task计算完会最终落地到磁盘
		
	Stage划分过程：拿到最后一个RDD，调用递归，从后往前递归，找到finalRDD的父RDD，开始RDD之间的依赖关系，
		如果是窄依赖，继续找父RDD的父RDD。如果是宽依赖，则划分为一个Stage。如此类推，指导所有的Stage划分完成。
		
	Task的生成过程：task的范围一定是在它的所属Stage的范围之内。
	一个task在执行的过程中会拿到一个线程，一个task对应一个分区，
	一个Stage里，有几个分区，就有几个task，
	在没有人为的更改分区数的情况下，一个Job的task的数量=Stage的数量 * 分区数
	
	RDD是个抽象类，实际上有很多子RDD：
		textFile：HadoopRDD
		flatMap:MapPartitionsRDD
		map:MapPartitionsRDD
		reduceByKey:ShuffledRDD
		sortBy:ShuffledRDD
		parallelize:ParallelCollectionRDD

RDD的缓存和缓存级别
	目的：使得依赖链条变短，提高计算效率
	缓存后，数据会缓存到每个节点的每个Executor对应的内存中

checkpoint检查点
	cache和checkpoint的区别：
		1、存储的位置不一样
		2、cache的数据安全性不高，checkpoint就是为了提高中间结果数据的安全性的
	什么时候使用cache或checkpoint
		1.某步骤计算特别耗时
		2.计算链条特别长
		3.发生shuffle之后

Spark集群启动流程

Spark任务提交流程

```

reduceByKey不发生shuffle的情况、shuffle的过程
![千锋_reduceByKey不发生shuffle的情况、shuffle的过程](/assets/千锋_reduceByKey不发生shuffle的情况、shuffle的过程.png)

stage划分和task的生成
![千锋_stage划分和task的生成](/assets/千锋_stage划分和task的生成.png)


集群启动流程和任务提交流程
![千锋_集群启动流程和任务提交流程](/assets/千锋_集群启动流程和任务提交流程.png)


## day05
```
自定义排序

RDD的分区器

自定义分区器

自定义分区器案例实现
```

## day06
```

自定义Accumulator累加器
	应用场景：Driver端定义一个共享变量，将数据累加到该变量上，
		如果直接用foreach或map等迭代算子，是无法将累加的结果返回到Driver端的，因为累加的过程是发生在Executor端的。
		一般是应用在计数的场景下，变量往往声明在Driver端。
	特性：变量在Driver端，累加的过程是在Executor端，
		在累加的过程中Executor端是无法读取其值的，如果想读取其值，只能是Driver才能读取
	使用过程：
		创建一个Accumulator
		注册
		调用Accumulator的add方法开始累加，这个过程是在Executor端发生的

广播变量
	应用场景：在提交作业后，task在执行的过程中，
		有一个或多个值需要在计算的过程中多次从Driver端拿取时，此时会必然会发生大量的网络IO，
		这时，最好用广播变量的方式，将Driver端的变量的值事先广播到每一个Worker端，
		以后再计算过程中只需要从本地拿取该值即可，避免网络IO，提高计算效率。
	广播变量在广播的时候，将Driver端的变量广播到每一个每一个Worker端，一个Worker端会收到一份仅一份该变量的值
	注意：广播的值必须是一个确切的值，不能广播RDD（因为RDD是一个数据的描述，没有拿到确切的值），
		如果想要广播RDD对应的值，需要将该RDD对应的数据获取到Driver端然后再进行广播。
		广播的数据是不可改变的。
		广播变量的数据不可太大，如果太大，会在Executor占用大量的缓存，相对于计算的时候的缓存就少很多。

案例练习

JdbcRDD

文件的输入输出

任务提交的4个阶段




```

broadcast
![千锋_broadcast](/assets/千锋_broadcast.png)


## day07
```

Spark SQL介绍

DataFrame和DataSet
	DataFrame：抽象的数据集，RDD和Schema的集合
		弱类型，我们在操作的时候可以像在操作二维表一样进行操作
	DataSet: 属于DataFrame的父类，DataFrame=Dataset[Row]，强类型

SparkSQL的开发流程（基本操作）
	DSL
	SQL

自定义函数（UDF、UDAF）

```

## day08
```

自定义函数

开窗函数

集成Hive
集成Hive的唯一目的就是为了让SparkSQL能够操作Hive元数据库中的表

集成步骤：
	将hive-site.xml复制到spark的conf目录中
	启动spark-shell的时候，需要将请求数据库的驱动包加载进来"--jars path"
用代码访问Hive元数据库：
	1、复制hive-site.xml hdfs-site.xml core-site.xml到resources
	2、开始代码编写
	3、将应用程序打包提交到集群

SparkSQL的JDBC操作

Kafka介绍

JMS介绍

Kafka的重要组件

Kafka集群搭建
```

千锋_Kafka的应用场景
![千锋_Kafka的应用场景](/assets/千锋_Kafka的应用场景.png)

Kafka主要组件介绍
![千锋_Kafka主要组件介绍](/assets/千锋_Kafka主要组件介绍.png)

## day09
```

Kafka的常用命令的操作

Kafka的一些常见的重要的问题

Kafka生产者和消费者的api练习

Streaming介绍

DStream的概念和理解
	DStream是将多个批次的算子都包含在了一个DStream里面，
	也就是说，一个DStream里可以有多个RDD，但这多个RDD都是一样的计算逻辑
	DStream的特性：
		DStream之间是有依赖关系的
		每隔一段时间（批次间隔）都会生成一个RDD
		每隔一段时间都会有一个函数作用到RDD上

transformations、output operations

```
Streaming
![千锋_Streaming](/assets/千锋_Streaming.png)


DStream
![千锋_DStream](/assets/千锋_DStream.png)


NatCat
![千锋_NatCat](/assets/千锋_NatCat.png)


## day10
```
三个特殊的原语：
	updateStateByKey：
		updataStateByKey会将历史结果拿到当前批次进行进一步的计算

	transform：
		借助这个原语可以操作DStream里的RDD，也就是可以用算子的方式间接操作DStream，大大丰富了DStream的api

	window operations：
		应用背景：计算的批次间隔不变，但每次展示的结果范围是多个批次间隔的范围，此时最好用SparkStreaming提供的窗口操作实现
		使用：需要提供两个重要的参数：窗口长度、滑动间隔

Streaming消费Kafka数据


```

窗口操作
![千锋_窗口操作](/assets/千锋_窗口操作.png)


## day11
```

Kafka-Streaming
	receiver和direct方式的理解和区别以及优缺点
	代码实现：direct（直连）方式维护offset的过程
	怎么解决offset失效问题
	怎么解决消费端数据积压问题（限速）
	streaming消费数据的一次仅一次语义的实现

Spark On Yarn
	Local模式
	Standalone模式
	On-Yarn模式
	Mesos
	
	应用背景：
		公司的使用习惯决定了资源调度系统的使用，节省了运维的工作量
		集群的资源是有限的，资源调度系统越少，资源的浪费越少
		
	配置：

Spark Core源码分析
	Spark集群启动流程





```

千锋_spark core的几个问题.txt
```
1、SparkContext是在哪一端生成的？
  
2、RDD是在哪一端生成的？

3、调用RDD的算子（Transformation和Action）是在哪一端调用的

4、RDD在调用Transformation和Action时需要传入一个函数，函数是在哪一端声明和传入的?

5、RDD在调用Transformation和Action时需要传入函数，请问传入的函数是在哪一端执行了函数的业务逻辑？

6、自定义的分区器这个类是在哪一端实例化的？

7、分区器中的getParitition(获取分区号)方法在哪一端调用的呢？

8、DAG是在哪一端被构建的？

9、DAG是在哪一端构建好的并被划分为一到多个Stage的

10、DAG是哪个类完成的切分Stage的功能？DAGSchedulerImpl
	
11、DAGScheduler将切分好的Stage以什么样的形式给TaskScheduler？TaskSet

12、Task是在哪一端生成的呢？ 

13、广播变量是在哪一端调用的方法进行广播的？

14、要广播的数据应该在哪一端先创建好再广播呢？ 
```


## 源码与调优
还未加入














## day02
```

```
